{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNmL2YA9el2N2Nl5JOZ/C9v"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#Importación Librerías\n"],"metadata":{"id":"mZWKuNciRBi5"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","path = '/content/drive/MyDrive/Proyecto Inteligencia Computacional/df_2.xlsx'\n","df = pd.read_excel(path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LlTKPamSRDCO","executionInfo":{"status":"ok","timestamp":1670947822403,"user_tz":180,"elapsed":6612,"user":{"displayName":"Lucas Orellana Jara","userId":"06105053239083253675"}},"outputId":"6c38f26f-d028-4ccf-fea2-81a5d9998a25"},"execution_count":145,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"markdown","source":["# Tratamiento de Datos"],"metadata":{"id":"5MmYVAfFblHv"}},{"cell_type":"markdown","source":["Eliminamos las variables con mas de 150 valores nulos"],"metadata":{"id":"5LYuWu2lRc7G"}},{"cell_type":"code","source":["df_copy = df.copy()\n","for i in df_copy:\n","  if df_copy[i].isna().sum() >= 150:\n","     df_copy = df_copy.drop(columns = [i]) "],"metadata":{"id":"KhL9LMQARNrm","executionInfo":{"status":"ok","timestamp":1670947822406,"user_tz":180,"elapsed":12,"user":{"displayName":"Lucas Orellana Jara","userId":"06105053239083253675"}}},"execution_count":146,"outputs":[]},{"cell_type":"markdown","source":["Por lo tanto juntaremos clases las clases SNIIb, SNIIn y SNII en una sola clase puesto que tiene pocos ejemplos\n"],"metadata":{"id":"UaweVVgnRoyk"}},{"cell_type":"code","source":["df_copy['classALeRCE']= df_copy['classALeRCE'].replace(['SNIIb','SNIIn'],'SNII')\n","df_copy['classALeRCE'].hist()\n","df_copy = df_copy.dropna()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":267},"id":"mn5AHBuqRQB-","executionInfo":{"status":"ok","timestamp":1670947822407,"user_tz":180,"elapsed":12,"user":{"displayName":"Lucas Orellana Jara","userId":"06105053239083253675"}},"outputId":"2582e843-4fb3-49c1-9cfc-14538580eee0"},"execution_count":147,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":["Separamos el dataset en entrenamiento y testeo, ademas de balancear los datos usando SMOTE "],"metadata":{"id":"metKUd20Rque"}},{"cell_type":"code","source":["import torch.nn as nn\n","import torch\n","import time"],"metadata":{"id":"7GbxD-28CMew","executionInfo":{"status":"ok","timestamp":1670947822407,"user_tz":180,"elapsed":11,"user":{"displayName":"Lucas Orellana Jara","userId":"06105053239083253675"}}},"execution_count":148,"outputs":[]},{"cell_type":"code","source":["torch.manual_seed(2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zXjswR0GCUUp","executionInfo":{"status":"ok","timestamp":1670947822408,"user_tz":180,"elapsed":11,"user":{"displayName":"Lucas Orellana Jara","userId":"06105053239083253675"}},"outputId":"35ad6b0d-e1b8-42a9-f19a-896f32f3834b"},"execution_count":149,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7f6ae86abbb0>"]},"metadata":{},"execution_count":149}]},{"cell_type":"code","source":["from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","\n","scaler = StandardScaler()\n","Le = LabelEncoder()\n","X = df_copy.drop(columns = ['classALeRCE', 'oid'])\n","X = scaler.fit_transform(X)\n","y = df_copy['classALeRCE'].values\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n","\n","#Ahora balanceamos los datos previamente a aplicar los modelos\n","from imblearn.over_sampling import SMOTE\n","sm= SMOTE(sampling_strategy = {'SLSN': 600 , 'SNII': 356*3, 'SNIa': 1394, 'SNIbc': 96*8})\n","X_train_smote, y_train_smote = sm.fit_resample(X_train, y_train)\n","X_train, y_train = X_train_smote, y_train_smote"],"metadata":{"id":"D7FrXMpqRXn5","executionInfo":{"status":"ok","timestamp":1670947822754,"user_tz":180,"elapsed":355,"user":{"displayName":"Lucas Orellana Jara","userId":"06105053239083253675"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"7869e5b5-ad9d-4d93-c6cd-b2c218300620"},"execution_count":150,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/imblearn/utils/_validation.py:299: UserWarning: After over-sampling, the number of samples (1068) in class SNII will be larger than the number of samples in the majority class (class #SNIa -> 923)\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/imblearn/utils/_validation.py:299: UserWarning: After over-sampling, the number of samples (1394) in class SNIa will be larger than the number of samples in the majority class (class #SNIa -> 923)\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["X_train.shape, y_train.shape, X_test.shape, y_test.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WqmIDSntCUvl","executionInfo":{"status":"ok","timestamp":1670947822756,"user_tz":180,"elapsed":355,"user":{"displayName":"Lucas Orellana Jara","userId":"06105053239083253675"}},"outputId":"79bdeec7-382d-4174-eec3-bd5a8faebcfe"},"execution_count":151,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((3830, 107), (3830,), (620, 107), (620,))"]},"metadata":{},"execution_count":151}]},{"cell_type":"code","source":["X_train = X_train.astype(np.float32)\n","X_test = X_test.astype(np.float32)\n","\n","for i in range(len(y_train)):\n","  if y_train[i] == 'SLSN':\n","    y_train[i] = 0\n","  elif y_train[i] == 'SNII':\n","    y_train[i] = 1\n","  elif y_train[i] == 'SNIa':\n","    y_train[i] = 2\n","  elif y_train[i] == 'SNIbc':\n","    y_train[i] = 3\n","\n","y_train = y_train.astype(np.int32)\n","\n","for i in range(len(y_test)):\n","  if y_test[i] == 'SLSN':\n","    y_test[i] = 0\n","  elif y_test[i] == 'SNII':\n","    y_test[i] = 1\n","  elif y_test[i] == 'SNIa':\n","    y_test[i] = 2\n","  elif y_test[i] == 'SNIbc':\n","    y_test[i] = 3\n","\n","y_test = y_test.astype(np.int32)"],"metadata":{"id":"4FUdldPMIaoI","executionInfo":{"status":"ok","timestamp":1670947822756,"user_tz":180,"elapsed":14,"user":{"displayName":"Lucas Orellana Jara","userId":"06105053239083253675"}}},"execution_count":152,"outputs":[]},{"cell_type":"code","source":["x_train = X_train.reshape(-1, X_train.shape[1]).astype('float32')\n","y_train = y_train\n","\n","x_val = X_test.reshape(-1, X_test.shape[1]).astype('float32')\n","y_val = y_test"],"metadata":{"id":"hVFM20e9DAVi","executionInfo":{"status":"ok","timestamp":1670947822757,"user_tz":180,"elapsed":14,"user":{"displayName":"Lucas Orellana Jara","userId":"06105053239083253675"}}},"execution_count":153,"outputs":[]},{"cell_type":"code","source":["x_train.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"inHOw1KvDRUq","executionInfo":{"status":"ok","timestamp":1670947822758,"user_tz":180,"elapsed":15,"user":{"displayName":"Lucas Orellana Jara","userId":"06105053239083253675"}},"outputId":"62291790-7811-4ca1-a58d-b0e92b149297"},"execution_count":154,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(3830, 107)"]},"metadata":{},"execution_count":154}]},{"cell_type":"code","source":["x_val = torch.from_numpy(x_val)\n","y_val = torch.from_numpy(y_val)"],"metadata":{"id":"zDzWBevPDUqx","executionInfo":{"status":"ok","timestamp":1670947822758,"user_tz":180,"elapsed":13,"user":{"displayName":"Lucas Orellana Jara","userId":"06105053239083253675"}}},"execution_count":155,"outputs":[]},{"cell_type":"code","source":["#Pack data with labels\n","train_data = list(zip(x_train, y_train))\n","test_data = list(zip(x_val, y_val))"],"metadata":{"id":"438LOAhFN7gR","executionInfo":{"status":"ok","timestamp":1670947822759,"user_tz":180,"elapsed":13,"user":{"displayName":"Lucas Orellana Jara","userId":"06105053239083253675"}}},"execution_count":156,"outputs":[]},{"cell_type":"code","source":["mse_criterion = nn.MSELoss()\n","cross_entropy_criterion = nn.BCELoss()"],"metadata":{"id":"Uo4npJ4BLUzZ","executionInfo":{"status":"ok","timestamp":1670947822759,"user_tz":180,"elapsed":13,"user":{"displayName":"Lucas Orellana Jara","userId":"06105053239083253675"}}},"execution_count":157,"outputs":[]},{"cell_type":"code","source":["class MLPClassifier(nn.Module):\n","    def __init__(self, n_features, layer_sizes):\n","        super().__init__()\n","        \n","        \"\"\"\n","        Acá definimos las capas ocultas.\n","        Ejemplo:\n","        Si recibimos layer_sizes = [10, 20], entonces se creará una red:\n","\n","        self.net = nn.Sequential(\n","            nn.Linear(n_features, 10),\n","            nn.ReLU(),\n","            nn.Linear(10, 20),\n","            nn.ReLU(),\n","            nn.Linear(20, 1),\n","            nn.Sigmoid(),\n","        )\n","\n","        Las dos primeras capas (y sus respectivas funciones de activación) se\n","        definirán en el loop for que se tiene acá abajo. La última capa (y la\n","        función sigmoide final) se agrega en el append que viene luego del loop for.\n","        \"\"\"\n","        \n","        layers = []\n","        prev_size = n_features\n","        for layer_size in layer_sizes:\n","            layers.append(nn.Linear(prev_size, layer_size))\n","            layers.append(nn.ReLU())\n","            prev_size = layer_size\n","\n","        layers.append(nn.Linear(prev_size, 4))\n","        layers.append(nn.Sigmoid())\n","\n","        self.net = nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        return self.net(x)"],"metadata":{"id":"OOTII8FLLYGZ","executionInfo":{"status":"ok","timestamp":1670947822760,"user_tz":180,"elapsed":14,"user":{"displayName":"Lucas Orellana Jara","userId":"06105053239083253675"}}},"execution_count":158,"outputs":[]},{"cell_type":"code","source":["class EarlyStopping:\n","    def __init__(self, n_epochs_tolerance):\n","        self.n_epochs_tolerance = n_epochs_tolerance\n","        self.epochs_with_no_improvement = 0\n","        self.best_loss = np.inf\n","\n","    def __call__(self, val_loss):\n","        # En cada llamada aumentamos el número de épocas en que no hemos mejorado\n","        self.epochs_with_no_improvement += 1\n","\n","        if val_loss <= self.best_loss:\n","            # Si efectivamente mejoramos (menor loss de validación) reiniciamos el número de épocas sin mejora\n","            self.best_loss = val_loss\n","            self.epochs_with_no_improvement = 0\n","\n","        # Retornamos True si debemos detenernos y False si aún no\n","        # Nos detenemos cuando el número de épocas sin mejora es mayor o igual que el número de épocas de tolerancia\n","        return self.epochs_with_no_improvement >= self.n_epochs_tolerance"],"metadata":{"id":"dGqQhCSvLaBm","executionInfo":{"status":"ok","timestamp":1670947822760,"user_tz":180,"elapsed":13,"user":{"displayName":"Lucas Orellana Jara","userId":"06105053239083253675"}}},"execution_count":159,"outputs":[]},{"cell_type":"code","source":["def train_model(\n","    model,\n","    train_dataset,\n","    val_dataset,\n","    max_epochs,\n","    criterion,\n","    batch_size,\n","    lr,\n","    early_stopping_tolerance=15,\n","    use_gpu=False\n","):\n","    if use_gpu:\n","        model.cuda()\n","\n","    early_stopping = EarlyStopping(n_epochs_tolerance=early_stopping_tolerance)\n","\n","    # Definición de dataloader\n","    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=use_gpu)\n","    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=len(val_dataset), shuffle=False, pin_memory=use_gpu)\n","\n","    # Optimizador\n","    optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n","\n","    # Listas para guardar curvas de entrenamiento\n","    curves = {\n","        \"train_acc\": [],\n","        \"val_acc\": [],\n","        \"train_loss\": [],\n","        \"val_loss\": []\n","    }\n","\n","    # Early stopping\n","    n_epochs_with_no_improvement = 0\n","    stop = False\n","\n","    t0 = time.perf_counter()\n","\n","    for epoch in range(max_epochs):\n","        cumulative_train_loss = 0\n","        cumulative_train_corrects = 0\n","\n","        # Entrenamiento del modelo\n","        model.train()\n","        for i, (x_batch, y_batch) in enumerate(train_loader):\n","            print(f\"\\rEpoch {epoch + 1}/{max_epochs} - Batch {i}/{len(train_loader)}\", end=\"\")\n","            if use_gpu:\n","                x_batch = x_batch.cuda()\n","                y_batch = y_batch.cuda()\n","\n","            # Predicción\n","            y_predicted = model(x_batch)\n","\n","            y_batch = y_batch.reshape(-1, 1).float()\n","\n","            # Cálculo de loss\n","            loss = criterion(y_predicted, y_batch)\n","\n","            # Actualización de parámetros\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","\n","            cumulative_train_loss += loss.item()\n","\n","            # Calculamos número de aciertos\n","            class_prediction = (y_predicted > 0.5)\n","            cumulative_train_corrects += (y_batch == class_prediction).sum()\n","\n","        train_loss = cumulative_train_loss / len(train_loader)\n","        train_acc = cumulative_train_corrects / len(train_dataset)\n","\n","        # Evaluación del modelo\n","        model.eval()\n","        x_val, y_val = next(iter(val_loader))\n","        if use_gpu:\n","            x_val = x_val.cuda()\n","            y_val = y_val.cuda()\n","\n","        y_predicted = model(x_val)\n","        y_val = y_val.reshape(-1, 1).float()\n","        loss = criterion(y_predicted, y_val)\n","\n","        class_prediction = (y_predicted > 0.5).long()\n","        val_acc = (y_val == class_prediction).sum() / y_val.shape[0]\n","        val_loss = loss.item()\n","\n","        curves[\"train_acc\"].append(train_acc)\n","        curves[\"val_acc\"].append(val_acc)\n","        curves[\"train_loss\"].append(train_loss)\n","        curves[\"val_loss\"].append(val_loss)\n","\n","        print(f\" - Train loss: {train_loss}, Train acc: {train_acc}, Val loss: {val_loss}, Val acc: {val_acc}\")\n","\n","        if early_stopping(val_loss):\n","            print(\"Early stopping.\")\n","            break\n","\n","    print()\n","    print(f\"Tiempo total de entrenamiento: {time.perf_counter() - t0:.4f} [s]\")\n","\n","    model.cpu()\n","\n","    return curves"],"metadata":{"id":"gfksxwP5LcmN","executionInfo":{"status":"ok","timestamp":1670947822761,"user_tz":180,"elapsed":14,"user":{"displayName":"Lucas Orellana Jara","userId":"06105053239083253675"}}},"execution_count":160,"outputs":[]},{"cell_type":"code","source":["# Entrenamiento MLP\n","\n","epochs = 100\n","lr = 0.1\n","batch_size = 64\n","early_stopping_tolerance = 15\n","use_gpu = False # CAMBIAR ESTO A True SI UTILIZAN UN ENTORNO CON GPU\n","\n","criterion = nn.BCELoss() # Entropía Cruzada\n","# criterion = nn.MSELoss() # Error Cuadrático Medio\n","\n","run_n_times = 5\n","curves_history = []\n","for run in range(run_n_times):\n","    print(f\"Entrenando corrida número {run + 1}/{run_n_times}\")\n","    # ----- Creacion de MLP\n","    model = MLPClassifier(\n","        n_features=28 * 28,\n","        layer_sizes=[25],\n","    )\n","\n","    # ----- Entrenamiento de MLP\n","    curves = train_model(\n","        model,\n","        train_data,\n","        test_data,\n","        max_epochs=epochs,\n","        criterion=criterion,\n","        batch_size=batch_size,\n","        lr=lr,\n","        early_stopping_tolerance=early_stopping_tolerance,\n","        use_gpu=use_gpu\n","    )\n","\n","    print()\n","\n","    curves_history.append(curves)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":436},"id":"oDlf8PnHLjkI","executionInfo":{"status":"error","timestamp":1670947849110,"user_tz":180,"elapsed":336,"user":{"displayName":"Lucas Orellana Jara","userId":"06105053239083253675"}},"outputId":"75261042-3935-4330-fbc9-54983f93b210"},"execution_count":162,"outputs":[{"output_type":"stream","name":"stdout","text":["Entrenando corrida número 1/5\n","\rEpoch 1/100 - Batch 0/60"]},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-162-6088596f1a08>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# ----- Entrenamiento de MLP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     curves = train_model(\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-160-783f541bad4a>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_dataset, val_dataset, max_epochs, criterion, batch_size, lr, early_stopping_tolerance, use_gpu)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;31m# Predicción\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0my_predicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-158-49cc5c4b4ab2>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (64x107 and 784x25)"]}]}]}